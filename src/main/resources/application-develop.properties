## 端口
server.port=8080
## 项目名(项目访问路径) http://localhost:8080/......
server.servlet.context-path=/anchor
# 指定静态资源路径
#spring.mvc.static-path-pattern=/static/**

## 自定义网站域名
community.path.domain = http://localhost:8080
# 用户头像暂存在这里，不纳入git
community.path.upload=d:/ProjectsOfCode/IdeaProjects/Anchor/upload



## MySQL
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/community?characterEncoding=utf-8&useSSL=false&serverTimezone=Asia/Shanghai
spring.datasource.username=root
spring.datasource.password=root123
# Mysql 5.0+ 版本使用 com.mysql.jdbc.Driver
# 如果是 8.0+ 的版本请改成 com.mysql.cj.jdbc.Driver
spring.datasource.driver-class-name=com.mysql.jdbc.Driver

## Mybatis
# 扫描 Mapper 文件的路径
mybatis.mapper-locations=classpath:mapper/*.xml
# 实体类位置
mybatis.type-aliases-package=com.reanon.community.entity
# insert 时 id自增长支持
mybatis.configuration.useGeneratedKeys=true
# 数据库的命名方式和驼峰命名方式转换
# 使得表中 user_name 与属性 userName 对应
mybatis.configuration.mapUnderscoreToCamelCase=true

## Spring Mail
spring.mail.host = smtp.sina.com
spring.mail.port = 465
spring.mail.username = anchor_community@sina.com
spring.mail.password = 53cc32b7ce31049b
spring.mail.protocol = smtps
spring.mail.properties.mail.smtp.ssl.enable = true


## Thymeleaf
spring.thymeleaf.cache=false

##  Redis
spring.redis.database = 11
spring.redis.host = localhost
spring.redis.port = 6379

## Kafka
spring.kafka.bootstrap-servers = localhost:9092
# 该字段见 Kafka 安装包中的 consumer.properties,可自行修改, 修改完毕后需要重启 Kafka
spring.kafka.consumer.group-id = community-consumer-group
# 设置自动提交与提交间隔
spring.kafka.consumer.enable-auto-commit = true
spring.kafka.consumer.auto-commit-interval = 3000


## Elasticsearch
# 7.x版本中cluster-nodes 和name 已经过时了
# spring.data.elasticsearch.cluster-nodes=127.0.0.1:9300
# spring.data.elasticsearch.cluster-name=my-application
elasticsearch.url=127.0.0.1:9200

## Spring线程池
# TaskExecutionProperties
spring.task.execution.pool.core-size=5
spring.task.execution.pool.max-size=15
spring.task.execution.pool.queue-capacity=100
# TaskSchedulingProperties - 定时执行线程池
spring.task.scheduling.pool.size=5

## Quartz
#spring.quartz.job-store-type = jdbc
#spring.quartz.scheduler-name = communityScheduler
#spring.quartz.properties.org.quartz.scheduler.instanceId = AUTO
#spring.quartz.properties.org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX
#spring.quartz.properties.org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate
#spring.quartz.properties.org.quartz.jobStore.isClustered = true
#spring.quartz.properties.org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool
#spring.quartz.properties.org.quartz.threadPool.threadCount = 5


## qiniu
#qiniu.key.access = 6NWps_pOPyTISxhI_xzPrjTzB2OscLcCwi5MobhS
#qiniu.key.secret = Htl8C-_oHhy_FUjirGEdDo0ztDeAI_WXoBfDqfpi
#qiniu.bucket.header.name = header--community
#qiniu.bucket.header.url = http://qnvxyvq1p.hd-bkt.clouddn.com
#
## Caffeine
#caffeine.posts.max-size = 15
#caffeine.posts.expire-seconds = 180

## logger
# 设置该包下的调试级别
#logging.level.com.reanon.community=debug
# 日志存储位置
#logging.file.name=